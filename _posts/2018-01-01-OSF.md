---
    author: kresnikwang
    comments: true
    date: 2018-01-01
    layout: post
    title: Object Scene Flow for Autonomous Vehicles
    categories:
    - paper
    tags:
    - scene flow
---

Object Scene Flow for Autonomous Vehicles

作者: Moritz Menze, Andreas Geiger

发表年份: 2015年

发表会议(期刊): CVPR

[项目主页](http://www.cvlibs.net/projects/objectsceneflow/)

# 1.Introduction
略

# 2. Related Work
略

# 3. Object Scene Flow
首先基于两个假设
1. 认为场景中的3D运动可以由一组超像素平面所估计出来
2. 假设场景中存在有限数量的形状规则的移动目标

之后我们定义一些量

\\(S\\) 表示超像素块的集合，

$O$ 表示目标的集合，

`$R_{i}$` 表示第 `$i$` 个超像素块在图像中的区域

`$s_{i} = (n_{i}, k_{i})^{T}$`, 其中 `$n_{i} \in R^{3}$` 是一个3D平面的法向量，
`$k_{i} \in \{1, ..., |O|\}$`, 表示这个像素块与哪一个目标相关。

`$o_{i} \in SE(3)$`， 表示3D物体的运动。

我们的目标是输入两帧连续的四张图像（双目）， 可以获得3D场景中的像素运动，
也就是获取 `$n_{i}, k_{i}, o_{i}$`.

于是我们可以构建下面的能量函数。

\\[
E(s, o) = \sum_{i \in S}\varphi_{i}(s_{i}, o) + \sum_{i ~ j} \psi_{ij}(s_{i}, s_{j})

\\]

其中前一项是数据项， 后一项是平滑项。

之后我们定义

$$
\varphi_{i}(s_{i}, o) = \sum_{j \in O}[k_{i} = j]*D_{i}(n_{i}, o_{j})
$$

其中的方括号是艾弗森括号， 里面的条件满足设为1， 条件不满足设为0.

其中
```math
D_{i}(n, o) = D_{i}^{stereo}(n, o) + D_{i}^{flow}(n, o) + D_{i}^{cross}(n, o)
```
将第一帧输入左边摄像头的图像作为参考视角， 与第一帧右边，第二帧左边， 第二帧右边，分别称作上面的 stereo， flow， cross

```math
D_{i}^{x}(n, o) = \sum_{p \in R_{i}}C_{x}(p, K(R_{x}(o) - t_{x}(o)*n^{T})K^{-1}p)
```
其中， 

`$K \in R^{3*3}$` 式摄像机的内参矩阵， 

`$R_{x}(o) \in R^{3*3}$` 是摄像机角度的旋转矩阵,

`$t_{x}(o) \in R^{3*1}$` 是摄像机的平移矩阵,

`$[R_{x}(o)|t_{x}(o)] \in R^{3*4}$`, 由相机外参矩阵和刚性运动共同决定.

`$n^{T}$`是空间中平面的法向量， 

这一项整体其实是一个单应矩阵（homography matrix）
， 这个矩阵一般用来描述空间中共面的点在不同视角下的图像中的像素对应关系， 可以通过取一些稀疏的特征点的匹配关系来求解， 由于矩阵有八个自由度， 一般需要四组特征点对来求解。

之后我们定义

```math
C_{x}(p, q) = \theta_{1x}C_{x}^{dense}(p, q) + \theta_{2x}C_{x}^{sparse}(p, q)
```

其中，
`$C_{x}^{dense}(p, q)$`, 由一个 `$5*5$` 的统计描述子的汉明距离定义。

```math
C_{x}^{sparse}(p, q) = \rho_{\tau_{1}}(||\pi_{x}(p) - q||_{2}),  p \in \Pi_{x}
```
其中，
```math
\rho_{\tau}(x) = min(|x|, \tau)
```

`$\pi_{x}$`根据稀疏匹配做出的对应， 
`$\Pi_{x}$` 表示已经建立好对应关系的点集。


## 3.2 Smoothness Term
平滑项定义为

```math
\psi_{ij}(s_{i}, s_{j}) = \theta_{3}\psi_{ij}^{depth}(n_{i}, n_{j}) + 
\theta_{4}\psi_{ij}^{orient}(n_{i}, n_{j}) +
\theta_{5}\psi_{ij}^{motion}(s_{i}, s_{j})
```
其中 `$\theta$` 为权值。其他项定义为

```math

\psi_{ij}^{depth}(n_{i}, n_{j}) = \sum_{p \in B_{ij}}\rho_{\tau_{2}}(d(n_{i}, p) - d(n_{j}, p))

\psi_{ij}^{orient}(n_{i}, n_{j}) = \rho_{\tau_{2}}(1 - \frac{|n_{i}^{T}n_{j}|}{||n_{i}||||n_{j}||})

\psi_{ij}^{motion}(s_{i}, s_{j}) = w(n_{i}, n_{j})*[k_{i} \neq k_{j}]

w(n_{i}, n_{j}) = exp(-\frac{\lambda}{|B_{ij}|}\sum_{p \in B_{ij}}(d(n_{i}, p) - d(n_{j}, p))^{2}) * \frac{|n_{i}^{T}n_{j}|}{||n_{i}||||n_{j}||}
```
其中， `$d(n, p)$`, 定义在像素`$ p $` 处与平面 `$ n $` 的差异。

`$ B_{ij} $` 是超像素块之间共享边界的像素集合。

## 3.3 Inference

优化上面的那个东西是一个NP难问题， 所以文章中采用
max-product particle belief propagation（MP-PBP）和sequential tree-reweighted message passing (TRW-S), 来进行优化。

利用 stereoSLIC来进行初始的超像素分割。

此外还需要进行一个稀疏光流的计算来进而估计运动。

# 4. Scene FLow Dataset and Annotation
提出了一个自己的数据库， 主要是车辆场景的scene flow

# 5. Experimental Results
我们需要的输入是
- 一个稀疏的光流匹配
- SGM(semi-global matching) 差异图
- stereoSLIC分割图

并利用一个三点的RANSAC来进行物体运动初始化。

效果不错， 可是完整版需要50min计算四张图像，
效果差一点的Fast版本也需要2min来计算。


# 6. 相关文献

2005 TRW-S

2012 PMBP

2012  Cross-Based Local Multipoint Filtering

2012 Factor Graphs and GTSAM

2014 Preserving Modes and Messages via Diverse Particle Selection

2014 Efficient Joint Segmentation Occlusion Labeling Stereo and Flow

2015 SPM-BP

2016 CSF

2017 ISF

2017 Mirror Flow

2017 RicFlow











































